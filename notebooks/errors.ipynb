{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_domains = [\"wiki\", \"news\", \"religious\", \"combined\"]\n",
    "models = {}\n",
    "vectorizers = {}\n",
    "results = {}\n",
    "\n",
    "for domain in source_domains:\n",
    "    txts_dev, golds_dev = read_data(f\"../langid4/data/domain.0.{domain}.dev\")\n",
    "\n",
    "    nb = load_model(f\"../models/naive_bayes/{domain}\")\n",
    "    vectorizer = load_model(f\"../models/naive_bayes/vectorizers/{domain}\")\n",
    "    models[domain] = nb\n",
    "    vectorizers[domain] = vectorizer\n",
    "\n",
    "    x_dev = vectorizer.transform(txts_dev)\n",
    "\n",
    "    pred = nb.predict(x_dev)\n",
    "    pred = list(map(lambda x: str(x), pred))\n",
    "\n",
    "    df = pd.DataFrame({\"txt\":txts_dev,\"gold\":golds_dev,\"pred\":pred})\n",
    "    results[domain] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "for (domain_name, df) in list(zip(results.keys(), list(results.values()))):\n",
    "    df.to_csv(f\"../results/error_analysis/{domain_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all pairs directed\n",
    "\n",
    "all_pairs = {}\n",
    "\n",
    "for domain in source_domains:\n",
    "    golds = results[domain][\"gold\"]\n",
    "    preds = results[domain][\"pred\"]\n",
    "\n",
    "    for i in range(len(golds)):\n",
    "        if golds[i] != preds[i]:\n",
    "            pair = (golds[i], preds[i])\n",
    "            if pair in all_pairs:\n",
    "                all_pairs[pair] += 1\n",
    "            else:\n",
    "                all_pairs[pair] = 1\n",
    "\n",
    "all_pairs_sorted = sorted(all_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "all_pairs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all pairs undirected\n",
    "\n",
    "all_pairs = {}\n",
    "\n",
    "domain = \"combined\"\n",
    "\n",
    "golds = results[domain][\"gold\"]\n",
    "preds = results[domain][\"pred\"]\n",
    "\n",
    "for i in range(len(golds)):\n",
    "    if golds[i] != preds[i]:\n",
    "        if (golds[i], preds[i]) in all_pairs:\n",
    "            all_pairs[(golds[i], preds[i])] += 1\n",
    "        elif (preds[i], golds[i]) in all_pairs:\n",
    "            all_pairs[(preds[i], golds[i])] += 1\n",
    "        else:\n",
    "            all_pairs[(golds[i], preds[i])] = 1\n",
    "\n",
    "all_pairs_sorted = sorted(all_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "all_pairs_sorted[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swadesh.swadesh import Swadesh\n",
    "\n",
    "path = \"/home/victor/Documents/ITU/Thesis/langid4/swadesh/data/swadesh_merged\"\n",
    "sw = Swadesh(path)\n",
    "\n",
    "for ((label1, label2), count) in all_pairs_sorted[:30]:\n",
    "    label1 = clean_language_name(label1)\n",
    "    label2 = clean_language_name(label2)\n",
    "\n",
    "    dist_score = sw.get_similarity(label1, label2)\n",
    "\n",
    "    # dists = get_lang_dists(label1, label2)\n",
    "    # if dists[\"lang2vec\"] is None or dists[\"lang2vec\"] == 0:\n",
    "    #     dist_score = dists[\"lang2vec_knn\"]\n",
    "    # else:\n",
    "    #     dist_score = dists[\"lang2vec\"]\n",
    "    \n",
    "    try:\n",
    "        dist_score = \"{:.4f}\".format(dist_score)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # print(f\"{label1}-{label2} ({count}): Language similarity ({dist_score})\")\n",
    "\n",
    "    print(f\"{label1}-{label2} & {dist_score} &  \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# find missing langs in swadesh list\n",
    "path = Path(\"/home/victor/Documents/ITU/Thesis/langid4/swadesh/data/swadesh_merged\")\n",
    "pairs = all_pairs_sorted[:30]\n",
    "\n",
    "for (pair, _) in pairs:\n",
    "    for lang in pair:\n",
    "        print(lang)\n",
    "        file_path = path / f\"{clean_language_name(lang)}.txt\"\n",
    "        if not file_path.exists():\n",
    "            print(clean_language_name(lang))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "top = all_pairs_sorted[:15]\n",
    "\n",
    "labels = [tuple(map(clean_language_name, pair)) for pair, _ in top]\n",
    "labels = [f\"{pair[0]}-{pair[1]}\" for pair in labels]\n",
    "\n",
    "values = [value for _, value in top]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=values, y=labels)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.title('Number of errors per language pair') \n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "top = all_pairs_sorted[:15]\n",
    "\n",
    "labels = [tuple(map(clean_language_name, pair)) for pair, _ in top]\n",
    "labels = [f\"{pair[0]}-{pair[1]}\" for pair in labels]\n",
    "\n",
    "values = [value for _, value in top]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.barplot(x=values, y=labels)\n",
    "plt.xlabel(\"Number of errors\", fontsize=16)\n",
    "plt.ylabel(\"Language pairs\", fontsize=16)\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(rotation=0, fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "\n",
    "plt.savefig(f\"Errorcounts.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "top = all_pairs_sorted[:15]\n",
    "\n",
    "labels = [tuple(map(clean_language_name, pair)) for pair, _ in top]\n",
    "labels = [f\"{pair[0]}-{pair[1]}\" for pair in labels]\n",
    "\n",
    "values = [value for _, value in top]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.barplot(x=labels, y=values)\n",
    "plt.ylabel(\"Number of errors\", fontsize=16)\n",
    "plt.xlabel(\"Language pairs\", fontsize=16)\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(rotation=0, fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "\n",
    "plt.savefig(f\"Errorcounts.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "top = all_pairs_sorted[:15]\n",
    "\n",
    "labels = [tuple(map(clean_language_name, pair)) for pair, _ in top]\n",
    "labels = [f\"{pair[0]}-{pair[1]}\" for pair in labels]\n",
    "\n",
    "values = [value for _, value in top]\n",
    "\n",
    "rank = np.arange(1, len(values) + 1) \n",
    "zipfian_curve = max(values) / rank\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.barplot(x=labels, y=values)\n",
    "\n",
    "plt.plot(labels, zipfian_curve, color=\"red\", marker=\"o\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.ylabel(\"Number of errors\", fontsize=20)\n",
    "plt.xlabel(\"Language pairs\", fontsize=20)\n",
    "plt.xticks(rotation=45, fontsize=17)\n",
    "plt.yticks(rotation=0, fontsize=17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.savefig(\"Errorcounts.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_per_domain = {}\n",
    "\n",
    "for domain in source_domains:\n",
    "    pairs = {}\n",
    "\n",
    "    golds = results[domain][\"gold\"]\n",
    "    preds = results[domain][\"pred\"]\n",
    "\n",
    "    for i in range(len(golds)):\n",
    "        if golds[i] != preds[i]:\n",
    "            pair = (golds[i], preds[i])\n",
    "            if pair in pairs:\n",
    "                pairs[pair] += 1\n",
    "            else:\n",
    "                pairs[pair] = 1\n",
    "\n",
    "    pairs_sorted = sorted(pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "    pairs_per_domain[domain] = pairs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_per_domain['combined'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot to see domain effect on number of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_per_domain['religious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [x for (x, _) in pairs_per_domain['combined']]\n",
    "\n",
    "number_of_errors_per_domain_by_language_pair = {}\n",
    "\n",
    "for target in targets:\n",
    "    all_domains = {}\n",
    "    for domain in source_domains[:-1]:\n",
    "        for (language, n_errors) in pairs_per_domain[domain]:\n",
    "            if (language == target):\n",
    "                all_domains[domain] = n_errors\n",
    "                break\n",
    "            all_domains[domain] = 0\n",
    "    number_of_errors_per_domain_by_language_pair[target] = all_domains\n",
    "    print(target, all_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_of_errors_per_domain_by_language_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_errors_per_domain_by_language_pair[('__label__cat', '__label__rus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_difference_in_top_2_domains_normalized(x):\n",
    "    (_, domains) = x\n",
    "    errors_list = domains.values()\n",
    "    errors_list_sorted = sorted(errors_list, reverse=True)\n",
    "    if sum(errors_list) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # print(errors_list_sorted[0], errors_list_sorted[1], sum(errors_list))\n",
    "    return (errors_list_sorted[0] - errors_list_sorted[1])/sum(errors_list)\n",
    "\n",
    "sorted_list = sorted(list(number_of_errors_per_domain_by_language_pair.items()), key=get_error_difference_in_top_2_domains_normalized, reverse=True)\n",
    "\n",
    "[(langs, get_error_difference_in_top_2_domains_normalized((langs, domains))) for (langs, domains) in sorted_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results['news']\n",
    "a = r[(r[\"gold\"] == \"__label__rus\") & (r[\"gold\"] == \"__label__cat\")]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results['combined']\n",
    "a = r[(r[\"gold\"] == \"__label__ukr\") & (r[\"pred\"] == \"__label__bul\")]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_domains = [\"wiki\", \"news\", \"religious\"]\n",
    "extensions = [\"train\", \"dev\"]\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for domain in source_domains:\n",
    "    for extension in extensions:\n",
    "        txts, golds = read_data(f\"../langid4/data/domain.0.{domain}.{extension}\")\n",
    "        all_data = pd.concat([all_data, pd.DataFrame({\"txt\":txts,\"gold\":golds})], ignore_index=True)\n",
    "\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = all_data[all_data[\"gold\"] == \"__label__hrv\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
