{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_domains = [\"wiki\", \"news\", \"religious\"]\n",
    "models = {}\n",
    "vectorizers = {}\n",
    "results = {}\n",
    "txts = {}\n",
    "golds = {}\n",
    "\n",
    "for domain in source_domains:\n",
    "    txts_dev, golds_dev = read_data(f\"../langid4/data/domain.0.{domain}.dev\")\n",
    "    txts[domain] = txts_dev\n",
    "    golds[domain] = golds_dev\n",
    "\n",
    "    nb = load_model(f\"../models/naive_bayes/{domain}\")\n",
    "    vectorizer = load_model(f\"../models/naive_bayes/vectorizers/{domain}\")\n",
    "    models[domain] = nb\n",
    "    vectorizers[domain] = vectorizer\n",
    "\n",
    "    x_dev = vectorizer.transform(txts_dev)\n",
    "\n",
    "    pred = nb.predict(x_dev)\n",
    "    pred = list(map(lambda x: str(x), pred))\n",
    "\n",
    "    df = pd.DataFrame({\"txt\":txts_dev,\"gold\":golds_dev,\"pred\":pred})\n",
    "    results[domain] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-domain feature selection approach\n",
    "\n",
    "This approach works, but reports slightly worse accuracy results compared to the baseline model using the 'combined' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_features(vectorizers):\n",
    "    all_feature_sets = [set(vec.get_feature_names_out()) for vec in vectorizers.values()]\n",
    "    \n",
    "    common_features = set.intersection(*all_feature_sets)\n",
    "    \n",
    "    return list(common_features)\n",
    "\n",
    "def create_domain_agnostic_vectorizer(vectorizers):\n",
    "    common_features = get_common_features(vectorizers)\n",
    "    \n",
    "    domain_agnostic_vectorizer = CountVectorizer()\n",
    "    \n",
    "    domain_agnostic_vectorizer.vocabulary_ = {\n",
    "        feature: idx for idx, feature in enumerate(common_features)\n",
    "    }\n",
    "    \n",
    "    return domain_agnostic_vectorizer\n",
    "\n",
    "def train_domain_agnostic_model(vectorizers, models):\n",
    "    domain_agnostic_vectorizer = create_domain_agnostic_vectorizer(vectorizers)\n",
    "    \n",
    "    combined_texts = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    for domain in source_domains:\n",
    "        txts_dev = txts[domain]\n",
    "        golds_dev = golds[domain]\n",
    "        \n",
    "        combined_texts.extend(txts_dev)\n",
    "        combined_labels.extend(golds_dev)\n",
    "    \n",
    "    domain_agnostic_model = MultinomialNB()\n",
    "    \n",
    "    x_combined = domain_agnostic_vectorizer.transform(combined_texts)\n",
    "    \n",
    "    domain_agnostic_model.fit(x_combined, combined_labels)\n",
    "    \n",
    "    return domain_agnostic_vectorizer, domain_agnostic_model\n",
    "\n",
    "\n",
    "(vectorizer, model) = train_domain_agnostic_model(vectorizers, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = vectorizer.transform([\"Hello, my name's jose\"])\n",
    "\n",
    "model.predict(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers[\"news\"].get_feature_names_out().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from my_utils import read_data\n",
    "\n",
    "source_domains = [\"wiki\", \"news\", \"religious\", \"combined\"]\n",
    "test_domains = [\"wiki\", \"news\", \"religious\", \"rights\", \"social\"]\n",
    "seed_number = 0\n",
    "scores = []\n",
    "\n",
    "\n",
    "for test_domain in test_domains:\n",
    "    dev_path = f\"../langid4/data/domain.{seed_number}.{test_domain}.dev\"\n",
    "    txts_dev, golds_dev = read_data(dev_path)\n",
    "    x_dev = vectorizer.transform(txts_dev)\n",
    "\n",
    "    y_pred = model.predict(x_dev)\n",
    "    accuracy = accuracy_score(golds_dev, y_pred)\n",
    "    scores.append(accuracy)\n",
    "    print((f\"Agnostic / {test_domain}: {accuracy}\"))\n",
    "\n",
    "print(scores)\n",
    "\n",
    "#                wiki   news   reli   comb\n",
    "# avgs           87.64, 86.54, 85.18, 91.82\n",
    "# avgs_glot500   83.14, 81.82, 81.16, 89.48\n",
    "\n",
    "# agnostic avg   80.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature weight based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weights(vectorizers, models):\n",
    "    feature_weights = {}\n",
    "    \n",
    "    for domain, vectorizer in vectorizers.items():\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        model = models[domain]\n",
    "        class_log_prior = model.class_log_prior_\n",
    "        feature_log_prob = model.feature_log_prob_\n",
    "        \n",
    "        for class_idx in range(len(class_log_prior)):\n",
    "            for feature_idx, feature_name in enumerate(feature_names):\n",
    "                weight = feature_log_prob[class_idx][feature_idx]\n",
    "                \n",
    "                if feature_name not in feature_weights:\n",
    "                    feature_weights[feature_name] = []\n",
    "                \n",
    "                feature_weights[feature_name].append(weight)\n",
    "    \n",
    "    avg_feature_weights = {\n",
    "        feature: np.mean(weights) \n",
    "        for feature, weights in feature_weights.items()\n",
    "    }\n",
    "    \n",
    "    return avg_feature_weights\n",
    "\n",
    "def create_domain_agnostic_weights(vectorizers, models):\n",
    "    avg_feature_weights = aggregate_weights(vectorizers, models)\n",
    "    \n",
    "    important_features = sorted(\n",
    "        avg_feature_weights.items(), \n",
    "        key=lambda x: abs(x[1]), \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    top_n = 1000\n",
    "    selected_features = [feat for feat, _ in important_features[:top_n]]\n",
    "    \n",
    "    domain_agnostic_vectorizer = vectorizers[list(vectorizers.keys())[0]].__class__()\n",
    "    domain_agnostic_vectorizer.vocabulary_ = {\n",
    "        feature: idx for idx, feature in enumerate(selected_features)\n",
    "    }\n",
    "    \n",
    "    combined_texts = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    for domain in source_domains:\n",
    "        combined_texts.extend(txts[domain])\n",
    "        combined_labels.extend(golds[domain])\n",
    "    \n",
    "    \n",
    "    domain_agnostic_model = MultinomialNB()\n",
    "    x_combined = domain_agnostic_vectorizer.transform(combined_texts)\n",
    "    domain_agnostic_model.fit(x_combined, combined_labels)\n",
    "    \n",
    "    return domain_agnostic_vectorizer, domain_agnostic_model\n",
    "\n",
    "\n",
    "(vectorizer_b, model_b) = create_domain_agnostic_weights(vectorizers, models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from my_utils import read_data, load_model, identity\n",
    "\n",
    "source_domains = [\"wiki\", \"news\", \"religious\", \"combined\"]\n",
    "test_domains = [\"wiki\", \"news\", \"religious\", \"rights\", \"social\"]\n",
    "seed_number = 0\n",
    "scores = []\n",
    "\n",
    "\n",
    "for test_domain in test_domains:\n",
    "    dev_path = f\"../langid4/data/domain.{seed_number}.{test_domain}.dev\"\n",
    "    txts_dev, golds_dev = read_data(dev_path)\n",
    "    x_dev = vectorizer_b.transform(txts_dev)\n",
    "\n",
    "    y_pred = model_b.predict(x_dev)\n",
    "    accuracy = accuracy_score(golds_dev, y_pred)\n",
    "    scores.append(accuracy)\n",
    "    print((f\"Agnostic / {test_domain}: {accuracy}\"))\n",
    "\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
